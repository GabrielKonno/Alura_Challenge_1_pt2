# -*- coding: utf-8 -*-
"""Alura_Challenge_1_pt2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t6T1XGFP5vgquhne-wOCVTH2TQcuMcC-
"""

import os
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from openai import OpenAI
from sklearn.preprocessing import LabelEncoder

"""#### Dicionário de dados

* `customerID`: número de identificação único de cada cliente
* `Churn`: se o cliente deixou ou não a empresa
* `gender`: gênero (masculino e feminino)
* `SeniorCitizen`: informação sobre um cliente ter ou não idade igual ou maior que 65 anos
* `Partner`:  se o cliente possui ou não um parceiro ou parceira
* `Dependents`: se o cliente possui ou não dependentes
* `tenure`:  meses de contrato do cliente
* `PhoneService`: assinatura de serviço telefônico
* `MultipleLines`: assisnatura de mais de uma linha de telefone
* `InternetService`: assinatura de um provedor internet
* `OnlineSecurity`: assinatura adicional de segurança online
* `OnlineBackup`: assinatura adicional de backup online
* `DeviceProtection`: assinatura adicional de proteção no dispositivo
* `TechSupport`: assinatura adicional de suporte técnico, menos tempo de espera
* `StreamingTV`: assinatura de TV a cabo
* `StreamingMovies`: assinatura de streaming de filmes
* `Contract`: tipo de contrato
* `PaperlessBilling`: se o cliente prefere receber online a fatura
* `PaymentMethod`: forma de pagamento
* `Charges.Monthly`: total de todos os serviços do cliente por mês
* `Charges.Total`: total gasto pelo cliente

# Conclusões das Análises dos Gráficos de Distribuição da Etapa Anterior


## Distribuições Desiguais:

- Temos um número muito mais alto de contagens para Não Churn que Sim Churn
- Senioridade está desigual, poucos clientes idosos.
- Dependentes está desigual
- Acúmulo de Tempo de contrato nos valores mais baixos
- PhoneService
- Online Security
- Online Backup
- Device Protection
- TechSupport
- StreamingTV
- StreamingMovies
- Acúmulo de ChargesMonthly e Total nas faixas menores, o que faz sentido pro ChargesTotal já que temos um número de clientes com poucos meses de contrato. Mas ChargesMonthly indica que temos um grande número de clientes com ticket baixo.

## Distribuições Iguais:
- A distribuiçõa de Gênero está equivalente.
- Parceiros está igual.
- Linhas Múltiplas
- InternetService
- Contract
- Paperless Billing
- Payment Method

# Hipóteses Até agora

- Entre homens e mulheres não vemos um padrão maior de churn por gênero.
- Entre os idosos, vemos uma taxa de cancelamento muito alta.
- Clientes que não possuem parceiros tendem a cancelar em torno de 2x mais.
- Existem mais clientes sem dependentes, porém os clientes com dependentes possuem uma taxa de cancelamento significativamente menor.
- A contagem alta de Churns em clientes com poucos meses de contrato demonstra uma taxa de cancelamento alta para os primeiros meses de contratação.
- Existe um número muito superior de clientes com contratação de serviços telefônicos, porém a taxa de churn aparenta estar proporcionalmente igual.
- Temos mais clientes SEM múltiplas linhas, mas a taxa de churn para os que tem é significativamente maior.
- A taxa de cancelamento para clientes com serviço de internet por fibra ótica extremamente alta, beirando os 50%. O que indica possível problema com o tipo de serviço.
- Temos mais clientes sem segurança online e com maior taxa de cancelamento do que aqueles que TEM segurança online.
- Mais clientes sem backup online, com uma taxa de cancelamento ligeiramente menor para aqueles que possuem backup online.
- O mesmo acontece para os clientes que possuem proteção de dispositivos.
- Clientes com suporte técnico tem uma taxa de churn 2x menor.
- Clientes sem StreamingTV possuem taxa de cancelamento menor, indicando possível problema com o tipo de serviço.
- O mesmo acontece para clientes sem StreamingMovies.
- Clientes com contrato mês a mês tem um Churn muito alto, em torno de 40%.
- Clientes com faturamento digital cancelam muito mais.
- Clientes que pagam com cheque eletrônico cancelam em torno de 40%.
- Não parece haver um padrão de churn em relação ao preço mensal.
- Distribuições desiguais podem fazer ser necessário utilizar uma reamostragem dos dados para evitar enviesamento do modelo. Utilizar outras métricas além de Acurácia, como F1-score, Recall e ROC-AUC.

# Importando o DF novo
"""

df_manipulacao = pd.read_csv('df_manipulacao.csv', index_col='ID')
df_manipulacao.head()

"""# Refazendo as Distribuições dos Dados"""

for coluna in df_manipulacao.columns:
    plt.figure(figsize=(8, 6))
    sns.histplot(data=df_manipulacao, x=coluna, kde=True)
    plt.title(f'Histograma da Variável: {coluna}')
    plt.xlabel(coluna)

# Distribuição das variáveis

for coluna in df_manipulacao.columns:
  fig = px.bar(df_manipulacao[coluna].value_counts(), x=df_manipulacao[coluna].value_counts().index, y=df_manipulacao[coluna].value_counts().values,
                color=df_manipulacao[coluna].value_counts().index,
                labels={'x': coluna, 'y': 'contagem'},
                title=f'Distribuição da variável: {coluna}')

  fig.update_layout(width=800, height=600)

  fig.show()  # Exibe o gráfico

for coluna in df_manipulacao.columns:
  fig = px.histogram(df_manipulacao, x=coluna, color='Cancelamento', barmode='group',
                      title=f'Contagem de {coluna} por Churn',
                      labels={'x': coluna, 'y': 'Contagem'})
  fig.update_layout(width=800, height=600)
  fig.show()

"""# Separa em Categóricas e Numéricas"""

df_numericas = df_manipulacao[['Tempo_De_Contrato', 'Cobrancas_Mensais', 'Cobrancas_Totais', 'Cobrancas_Diarias']]
df_categoricas = df_manipulacao.drop(columns=['Tempo_De_Contrato', 'Cobrancas_Mensais', 'Cobrancas_Totais', 'Cobrancas_Diarias'])

df_numericas.head()

df_categoricas.head()

"""# Fazer Codificação das Variáveis Categóricas

Como o objetivo é fazer a previsão de churn, vamos utilizar Árvores de Decisão para isso. Então não vamos ter problemas com label encoding.
"""

encoder = LabelEncoder()

for coluna in df_categoricas.columns:
    df_categoricas[coluna] = encoder.fit_transform(df_categoricas[coluna])

df_categoricas.head()

df_final = pd.merge(df_numericas, df_categoricas, on = 'ID', how = 'inner')
df_final.head()

"""# Data Frame Final

Agora que temos o df final e transformado, podemos focar mais nas análises dos dados em si do que na integridade e formato dos dados.

1. Relembrar as informações gerais do dataset.
2. Verificar a Distribuição das variáveis
3. Analisar outliers
4. Analisar a variável target (Churn - Cancelamento)
5. Correlação entre variáveis
6. Relação das Variáveis com a variável target.

"""

df_final.info()

df_final.shape

df_final.describe()

correlacao = df_final.corr()
plt.figure(figsize=(18, 6))
sns.heatmap(correlacao, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)

plt.title("Heatmap de Correlação")
plt.show()

"""# Resumo da Etapa Anterior

1. Extraímos os Dados
2. Criamos o DataFrame
3. Exploramos os dados e identificamos tamanho, variáveis, tipos de dados, valores faltantes.
4. Corrigimos os valores faltantes e removemos, ajustamos os nomes das colunas, fizemos uma investigação inicial da distribuição dos dados.
5. Investigamos melhor a distribuição dos dados e procuramos padrões entre as distribuições da variável target com as variáveis independentes.
6. Levantamos hipóteses das análises.
7. Traduzimos os nomes das colunas automaticamente utilizando API da OpenAI (para aprendizado).
8. Criamos a coluna de Cobranças Diária (desafio extra).
9. Salvamos o DF em um arquivo CSV.


# Resumo Até Agora
1. Importamos o CSV criado na etapa anterior.
2. Separamos o DF em variáveis numéricas e categóricas.
3. Fizemos Encoding das variáveis categóricas utilizando Label Encoder.
4. Unimos as variáveis numéricas com as categóricas após a codificação.
5. Puxamos as informações estatísticas e gerais do data frame para relembrar.
6. Fizemos um Heatmap de correlação entre as variáveis.

# Conclusões das Análises dos Gráficos de Distribuição


## Distribuições Desiguais:

- Temos um número muito mais alto de contagens para Não Churn que Sim Churn
- Senioridade está desigual, poucos clientes idosos.
- Dependentes está desigual
- Acúmulo de Tempo de contrato nos valores mais baixos
- PhoneService
- Online Security
- Online Backup
- Device Protection
- TechSupport
- StreamingTV
- StreamingMovies
- Acúmulo de ChargesMonthly e Total nas faixas menores, o que faz sentido pro ChargesTotal já que temos um número de clientes com poucos meses de contrato. Mas ChargesMonthly indica que temos um grande número de clientes com ticket baixo.

## Distribuições Iguais:
- A distribuiçõa de Gênero está equivalente.
- Parceiros está igual.
- Linhas Múltiplas
- InternetService
- Contract
- Paperless Billing
- Payment Method

## Hipóteses Levantadas

- Entre homens e mulheres não vemos um padrão maior de churn por gênero.
- Entre os idosos, vemos uma taxa de cancelamento muito alta.
- Clientes que não possuem parceiros tendem a cancelar em torno de 2x mais.
- Existem mais clientes sem dependentes, porém os clientes com dependentes possuem uma taxa de cancelamento significativamente menor.
- A contagem alta de Churns em clientes com poucos meses de contrato demonstra uma taxa de cancelamento alta para os primeiros meses de contratação.
- Existe um número muito superior de clientes com contratação de serviços telefônicos, porém a taxa de churn aparenta estar proporcionalmente igual.
- Temos mais clientes SEM múltiplas linhas, mas a taxa de churn para os que tem é significativamente maior.
- A taxa de cancelamento para clientes com serviço de internet por fibra ótica extremamente alta, beirando os 50%. O que indica possível problema com o tipo de serviço.
- Temos mais clientes sem segurança online e com maior taxa de cancelamento do que aqueles que TEM segurança online.
- Mais clientes sem backup online, com uma taxa de cancelamento ligeiramente menor para aqueles que possuem backup online.
- O mesmo acontece para os clientes que possuem proteção de dispositivos.
- Clientes com suporte técnico tem uma taxa de churn 2x menor.
- Clientes sem StreamingTV possuem taxa de cancelamento menor, indicando possível problema com o tipo de serviço.
- O mesmo acontece para clientes sem StreamingMovies.
- Clientes com contrato mês a mês tem um Churn muito alto, em torno de 40%.
- Clientes com faturamento digital cancelam muito mais.
- Clientes que pagam com cheque eletrônico cancelam em torno de 40%.
- Não parece haver um padrão de churn em relação ao preço mensal.
- Distribuições desiguais podem fazer ser necessário utilizar uma reamostragem dos dados para evitar enviesamento do modelo. Utilizar outras métricas além de Acurácia, como F1-score, Recall e ROC-AUC.

# Oversample

Como a distribuição das classes das variáveis não estão necessariamente iguais, precisamos realizar o oversample.

A escolha do oversample sobre undersample é feita porque o dataset não tem uma quantidade tão expressiva e, considerando a distribuição da variável target, perderíamos cerca de 33% das informações.
"""

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

X = df_final.drop(columns='Cancelamento')
y = df_final['Cancelamento']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

print("Distribuição original:", y_train.value_counts())
print("Distribuição após SMOTE:", pd.Series(y_train_res).value_counts())

"""# Finalizamos a etapa de Exploração, Entendimento, Limpeza e Manipulação dos Dados.

# Criando Modelos

Vou testar 3 modelos:
- Regressão Logística
- Random Forest
- Gradient Boosting (XGBoost)

Utilizaremos Matriz de confusão para verificar falsos positivos e negativos.

Para métricas, colocaremos (em ordem de prioridade):
- Recall para validar os falsos negativos
- Acurácia balanceada, por haver desbalanceamento de classes e valorizar o acerto de cada classe, para ver um desempenho geral do modelo;
- AUC Para comparação de modelos;
- Precisão para validar o número de falsos positivos;
- F1 Score para uma avaliação balanceada entre precisão e recall.

## Regressão Logística
"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, classification_report, ConfusionMatrixDisplay

lr = LogisticRegression(max_iter=200)

lr.fit(X_train_res, y_train_res)

lr_y_pred = lr.predict(X_test)
lr_y_pred_proba = lr.predict_proba(X_test)[:, 1]

# Matriz de Confusão para visualizar falsos positivos e negativos
cm = confusion_matrix(y_test, lr_y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr.classes_)
disp.plot(cmap='Blues')
plt.title("Matriz de Confusão")
plt.show()

# Avaliação
recall_lr = recall_score(y_test, lr_y_pred)
acc_score_lr = lr.score(X_test, y_test)
acc_balanceada_lr = balanced_accuracy_score(y_test, lr_y_pred)
auc_lr = roc_auc_score(y_test, lr_y_pred_proba)
f1_lr = f1_score(y_test, lr_y_pred)
precision_lr = precision_score(y_test, lr_y_pred)


print(f"Recall: {recall_lr * 100:.2f}%")
print(f"Acurácia no teste: {acc_score_lr * 100:.2f}%")
print(f"Acurácia Balanceada: {acc_balanceada_lr * 100:.2f}%")
print(f"AUC: {auc_lr * 100:.2f}%")
print(f"Precisão: {f1_lr * 100:.2f}%")
print(f"F1 Score: {precision_lr * 100:.2f}%")

"""# Criando modelos seguidos e um DF para comparação."""

# Instanciando Modelos
modelo_lr = LogisticRegression(max_iter=200)
modelo_rf = RandomForestClassifier(random_state=42)
modelo_xgb = XGBClassifier(random_state=42)

# Dicionário de Modelos
modelos = {
    'Logistic Regression': modelo_lr,
    'Random Forest': modelo_rf,
    'Gradient Boosting': modelo_xgb
}

metrics = []

# Treinamento de Modelos
for nome_modelo, modelo in modelos.items():
    modelo.fit(X_train_res, y_train_res)
    y_pred = modelo.predict(X_test)
    y_pred_proba = modelo.predict_proba(X_test)[:, 1]

    metrics.append({
        'Modelo': nome_modelo,
        'Recall': recall_score(y_test, y_pred),
        'Acurácia_Bal': balanced_accuracy_score(y_test, y_pred),
        'AUC': roc_auc_score(y_test, y_pred_proba),
        'F1-score': f1_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred)
    })

# Converter a lista de dicionários em um DataFrame
df_metrics = pd.DataFrame(metrics)
df_metrics

"""# Tunning de Hiperparâmetros"""

from sklearn.model_selection import GridSearchCV

# Instanciando Modelos
modelo_lr = LogisticRegression()
modelo_rf = RandomForestClassifier(random_state=42)
modelo_xgb = XGBClassifier(random_state=42)

# Dicionário de Modelos
modelos = {
    'Logistic Regression': modelo_lr,
    'Random Forest': modelo_rf,
    'Gradient Boosting': modelo_xgb
}


# Grids de Hiperparâmetros

param_grids = {
    'Logistic Regression': {
        'C': [0.01, 0.1],
        'penalty': ['l1'],
        'solver': ['liblinear'],
        'max_iter': [200, 300]
    },
    'Random Forest': {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1],
        'max_features': ['auto', 'sqrt']
    },
    'Gradient Boosting': {
        'n_estimators': [50, 100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7]
    }
}

# Lista de Métricas

metrics = []

# Treinamento de Modelos
for nome_modelo, modelo in modelos.items():
  print(f"Ajustando hiperparâmetros para {nome_modelo}...")

  # Cria o GridSearchCV usando o grid correspondente
  grid = GridSearchCV(estimator=modelo,
                      param_grid=param_grids[nome_modelo],
                      cv=5,
                      scoring='recall',
                      n_jobs=-1,
                      verbose=1)
  grid.fit(X_train_res, y_train_res)

  # Obtém o melhor modelo encontrado
  melhor_modelo = grid.best_estimator_
  print(f"Melhores parâmetros para {nome_modelo}:", grid.best_params_)

  # Fazendo Predições
  y_pred = melhor_modelo.predict(X_test)
  y_pred_proba = melhor_modelo.predict_proba(X_test)[:, 1]

  # Calculando Métricas e Adicionando
  metrics.append({
      'Modelo': nome_modelo,
      'Recall': recall_score(y_test, y_pred),
      'Acurácia_Bal': balanced_accuracy_score(y_test, y_pred),
      'AUC': roc_auc_score(y_test, y_pred_proba),
      'F1-score': f1_score(y_test, y_pred),
      'Precision': precision_score(y_test, y_pred)
  })

# Converter a lista de dicionários em um DataFrame
df_metrics_tunned = pd.DataFrame(metrics)
df_metrics_tunned

"""# Conclusão

Os modelos foram otimizados e, com base nas métricas, Logistic Regression parece ser uma melhor opção. Ainda que o recall tenha dado um score menor, as outras métricas estão melhores e suportam a escolha pela diferença pequena no Recall.
"""

